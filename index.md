---
layout: page
#subtitle: Yu-Wen Chen 
#subtitle: This is where I will tell my friends way too much about me ..
#cover-img: /assets/img/path.jpg
#/assets/img/thumb.png
#thumbnail-img: /assets/img/thumb.png
#share-img: /assets/img/thumb.png
---

<br />
<img src="/assets/img/private/IMG.png" align="left" width="200px" style="vertical-align:middle;margin:0px 30px 0px 0px" />
<h2>Yu-Wen Chen (陳郁文)</h2><br />
Ph.D. Student,<br />
Department of Computer sciences,<br />
Columbia University<br />
<br clear="left"/>

Hello! I am Yu-Wen Chen.<br />
<div style="text-align: justify"> 

I am a second-year Ph.D. student in the <a href="https://www.cs.columbia.edu/areas/speech/">Speech Lab</a> at Columbia University, under the guidance of Professor <a href="https://www.cs.columbia.edu/~julia/">Julia Hirschberg</a>. My previous research includes speech pronunciation assessment, speech quality assessment, and speech enhancement. Currently, I am interested in medical-related tasks such as assessing patients' health conditions based on their voice. In general, my research interests focus on the speech processing tasks that can make human life more convenient and productive.


Before joining the Speech Lab, I worked as a research assistant in the <a href="https://bio-asplab.citi.sinica.edu.tw/">Bio-ASP Lab</a>, Academia Sinica, where I am conducting research with Professor <a href="https://www.citi.sinica.edu.tw/pages/yu.tsao/index_en.html">Yu Tsao</a>. Prior to Bio-ASP Lab, I earned my master’s degree at National Taiwan University (NTU) under the guidance of Professor <a href="https://www.ee.ntu.edu.tw/profile1.php?teacher_id=901166">Tian-Li Yu</a>, and my bachelor's degree at National Cheng Kung University. 

<br />

</div>

<h3>Publications</h3>

<h4>Preprints</h4>

* <b>Chen, Y. W.</b>, Yu, Z., & Hirschberg, J. (2023). MultiPA: a multi-task speech pronunciation assessment system for a closed and open response scenario. arXiv preprint arXiv:2308.12490. <a href="https://arxiv.org/abs/2301.04120">[pdf]</a> <a href="https://github.com/yuwchen/MultiPA">[Github]</a><br />
* <b>Chen, Y. W.</b>, Hirschberg, J., & Tsao, Y. (2023). Noise robust speech emotion recognition with signal-to-noise ratio adapting speech enhancement. arXiv preprint arXiv:2309.01164. <a href="https://arxiv.org/abs/2309.01164">[pdf]</a> <a href="https://github.com/yuwchen/NRSER">[Github]</a><br />
  
<h4>Conference Papers</h4>

* <b>Chen, Y. W.</b>, & Tsao, Y. (2022). <b>“InQSS: a speech intelligibility and quality assessment model using a multi-task learning network.”</b> INTERSPEECH, 3088-3092. <a href="https://arxiv.org/pdf/2111.02585.pdf">[pdf]</a> <a href="https://github.com/yuwchen/InQSS">[Github]</a> <br /> 
* <b>Chen, Y. W.</b>., Hung, K. H., Chuang, S. Y., Sherman, J., Huang, W. C., Lu, X., & Tsao, Y. (2021) <b>“EMA2S: An end-to-end multimodal articulatory-to-speech system.”</b> IEEE International Symposium on Circuits and Systems (ISCAS), 1-5.  <a href="https://arxiv.org/pdf/2102.03786.pdf">[pdf]</a> <br />
* <b>Chen, Y. W.</b>, Hung, K. H., Chuang, S. Y., Sherman, J., Lu, X., & Tsao, Y. (2021) <b>“A study of incorporating articulatory movement information in speech enhancement.”</b> IEEE European Signal Processing Conference (EUSIPCO), 496-500. <a href="https://arxiv.org/pdf/2011.01691.pdf">[pdf]</a>

<h4>Journal Papers</h4>

* <b>Chen, Y. W.</b>, Wang, H. M., & Tsao, Y. (2023) <b>“BASPRO: A balanced script producer for speech corpus collection based on the genetic algorithm.”</b> APSIPA Transactions on Signal and Information Processing: Vol. 12: No. 3. <a href="https://arxiv.org/abs/2301.04120">[pdf]</a> <a href="https://github.com/yuwchen/BASPRO">[Github]</a> <br />
* <b>Chen, Y. W.</b>, Hung, K. H., Li, Y. J., Kang, A. C. F., Lai, Y. H., Liu, K. C., ... & Tsao, Y. (2022) <b>“CITISEN: a deep learning-based speech signal-processing mobile application.”</b> IEEE Access, 10, 46082-46099. <a href="https://github.com/yuwchen/CITISEN">[pdf]</a> <a href="https://github.com/yuwchen/BASPRO">[Github]</a> <br />

<br />
